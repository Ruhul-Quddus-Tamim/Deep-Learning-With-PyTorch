{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFOWKCuiqCPN"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_top?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2022-01-01\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
        "</a> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-kPuYM0qCPP"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qDtbDs1qCPQ"
      },
      "source": [
        "<h1><h1>Pre-trained-Models with PyTorch </h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo7bESBGqCPS"
      },
      "source": [
        "Using pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18\n",
        "\n",
        "<ul>\n",
        "<li>change the output layer</li>\n",
        "<li> train the model</li> \n",
        "<li>  identify  several  misclassified samples</li> \n",
        " </ul>\n",
        "You will take several screenshots of your work and share your notebook. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKp8UaCNqCPT"
      },
      "source": [
        "<h2>Table of Contents</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPJwzL_EqCPT"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"https://#download_data\"> Download Data</a></li>\n",
        "    <li><a href=\"https://#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
        "    <li><a href=\"https://#data_class\"> Dataset Class</a></li>\n",
        "    <li><a href=\"https://#Question_1\">Question 1</a></li>\n",
        "    <li><a href=\"https://#Question_2\">Question 2</a></li>\n",
        "    <li><a href=\"https://#Question_3\">Question 3</a></li>\n",
        "</ul>\n",
        " </div>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGzgM3UCqCPU"
      },
      "source": [
        "<h2 id=\"download_data\">Download Data</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MVL4yiiqCPU"
      },
      "source": [
        "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG0sloXnqCPV",
        "outputId": "779085b0-a84a-494a-f640-26ad8450dfd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-18 13:45:37--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2598656062 (2.4G) [application/zip]\n",
            "Saving to: ‘Positive_tensors.zip’\n",
            "\n",
            "Positive_tensors.zi 100%[===================>]   2.42G  37.2MB/s    in 68s     \n",
            "\n",
            "2022-10-18 13:46:45 (36.4 MB/s) - ‘Positive_tensors.zip’ saved [2598656062/2598656062]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wonJAloBqCPX"
      },
      "outputs": [],
      "source": [
        "!unzip -q Positive_tensors.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g17RCDjVqCPY",
        "outputId": "606fbc66-3534-404d-91d0-7e9c3a14cb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-18 13:48:45--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2111408108 (2.0G) [application/zip]\n",
            "Saving to: ‘Negative_tensors.zip’\n",
            "\n",
            "Negative_tensors.zi 100%[===================>]   1.97G  34.9MB/s    in 55s     \n",
            "\n",
            "2022-10-18 13:49:41 (36.5 MB/s) - ‘Negative_tensors.zip’ saved [2111408108/2111408108]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
        "!unzip -q Negative_tensors.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcUPtt_UqCPZ"
      },
      "source": [
        "We will install torchvision:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpVV_6k-qCPZ",
        "outputId": "b19c98ea-9f8b-41ae-ead8-bd293df2e750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX8Ic0dqqCPZ"
      },
      "source": [
        "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxkPqnQmqCPZ"
      },
      "source": [
        "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEztEe6xqCPa",
        "outputId": "39a94bbf-675c-4ede-c8b9-75060b6b5110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f498cb59870>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import pandas\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch \n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import h5py\n",
        "import os\n",
        "import glob\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4E6GfIqzqCPb"
      },
      "outputs": [],
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVAiGzOzqCPc"
      },
      "source": [
        "<!--Empty Space for separating topics-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4oJZF12qCPc"
      },
      "source": [
        "<h2 id=\"data_class\">Dataset Class</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kal8YQVrqCPd"
      },
      "source": [
        "This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgUmp26sqCPd",
        "outputId": "6a936dd8-8f8b-4911-d28b-b389697b14f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# Create your own dataset object\n",
        "\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,transform=None,train=True):\n",
        "        directory=\"\"\n",
        "        positive=\"Positive_tensors\"\n",
        "        negative='Negative_tensors'\n",
        "\n",
        "        positive_file_path=os.path.join(directory,positive)\n",
        "        negative_file_path=os.path.join(directory,negative)\n",
        "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
        "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
        "        number_of_samples=len(positive_files)+len(negative_files)\n",
        "        self.all_files=[None]*number_of_samples\n",
        "        self.all_files[::2]=positive_files\n",
        "        self.all_files[1::2]=negative_files \n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        #torch.LongTensor\n",
        "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
        "        self.Y[::2]=1\n",
        "        self.Y[1::2]=0\n",
        "        \n",
        "        if train:\n",
        "            self.all_files=self.all_files[0:30000]\n",
        "            self.Y=self.Y[0:30000]\n",
        "            self.len=len(self.all_files)\n",
        "        else:\n",
        "            self.all_files=self.all_files[30000:]\n",
        "            self.Y=self.Y[30000:]\n",
        "            self.len=len(self.all_files)     \n",
        "       \n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    # Getter\n",
        "    def __getitem__(self, idx):\n",
        "               \n",
        "        image=torch.load(self.all_files[idx])\n",
        "        y=self.Y[idx]\n",
        "                  \n",
        "        # If there is any transform method, apply it onto the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y\n",
        "    \n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXnhM3PRqCPe"
      },
      "source": [
        "We create two dataset objects, one for the training data and one for the validation data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPQzGlTsqCPe",
        "outputId": "f7eb3a2d-d1c7-4b3c-ca8e-0f90a9a50c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "train_dataset = Dataset(train=True)\n",
        "validation_dataset = Dataset(train=False)\n",
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Lp3VyGqCPe"
      },
      "source": [
        "<h2 id=\"Question_1\">Question 1</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeWncbJ9qCPe"
      },
      "source": [
        "<b>Prepare a pre-trained resnet18 model :</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWRnGk08qCPe"
      },
      "source": [
        "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "72df0417278f4a698d715a40631351b9",
            "ef6ee786e998456e93d77cf3982ddb42",
            "4db41434c958423d8a4608e5379fa8e9",
            "472a995540044d96a5db2d9031b63842",
            "77a53d05b2d7453d97d7180b209b765f",
            "0bfb8ee84d8648928020eaf68ac7cee8",
            "a196af67e41f472da795049709b34dc3",
            "516643faa6ac407699f0a4a356c0b689",
            "39f98be79d1c405bb20d15b8187df4d9",
            "c4a160da3c57443b937c9aab8839fa5b",
            "d0353bd81de74a75a1470d042c5c095d"
          ]
        },
        "id": "sYKCZ0w3qCPf",
        "outputId": "84752aa8-39cb-4a39-d827-96d746e03a1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72df0417278f4a698d715a40631351b9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Step 1: Load the pre-trained model resnet18\n",
        "model = models.resnet18(pretrained = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juvMQBkOqCPf"
      },
      "source": [
        "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TC_9IsMMqCPf"
      },
      "outputs": [],
      "source": [
        "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uPOUZQVqCPf"
      },
      "source": [
        "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqUDlikKqCPf"
      },
      "source": [
        "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(512, 2)"
      ],
      "metadata": {
        "id": "NEqEMaakE35g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odFBFDOoqCPh"
      },
      "source": [
        "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXRCsWaeqCPh",
        "outputId": "0ddd4a89-0424-465b-82bd-73b934a80b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gab4MlrgqCPi"
      },
      "source": [
        "<h2 id=\"Question_2\">Question 2: Train the Model</h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JFO7PrwqCPi"
      },
      "source": [
        "In this question you will train your, model:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh0NPM0HqCPi"
      },
      "source": [
        "<b>Step 1</b>: Create a cross entropy criterion function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "f8VUe2sBqCPj"
      },
      "outputs": [],
      "source": [
        "# Step 1: Create the loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm01WDnEqCPj"
      },
      "source": [
        "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "k0nQ0udsqCPj"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = 100)\n",
        "validation_loader = DataLoader(dataset = validation_dataset, batch_size = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCbcvvfpqCPk"
      },
      "source": [
        "<b>Step 3</b>: Use the following optimizer to minimize the loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ioLoJm0fqCPk"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG-YK_vUqCPl"
      },
      "source": [
        "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uDlc79hJqCPl"
      },
      "outputs": [],
      "source": [
        "n_epochs=1\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "correct=0\n",
        "N_test=len(validation_dataset)\n",
        "N_train=len(train_dataset)\n",
        "start_time = time.time()\n",
        "#n_epochs\n",
        "\n",
        "Loss=0\n",
        "start_time = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for x, y in train_loader:\n",
        "      model.train() \n",
        "      #clear gradient \n",
        "      optimizer.zero_grad()\n",
        "      #make a prediction \n",
        "      z = model(x)\n",
        "      # calculate loss \n",
        "      loss = criterion(z, y)\n",
        "      # calculate gradients of parameters \n",
        "      loss.backward()\n",
        "      # update parameters\n",
        "      optimizer.step()\n",
        "      loss_list.append(loss.data)\n",
        "\n",
        "    correct=0\n",
        "    for x_test, y_test in validation_loader:\n",
        "      # set model to eval\n",
        "      model.eval()\n",
        "  \n",
        "      #make a prediction\n",
        "      z = model(x_test) \n",
        "      #find max\n",
        "      _, yhat = torch.max(z.data, 1) \n",
        "       \n",
        "      #Calculate misclassified  samples in mini-batch \n",
        "      #hint +=(yhat==y_test).sum().item()\n",
        "      correct += (yhat==y_test).sum().item()\n",
        "   \n",
        "    accuracy=correct/N_test\n",
        "    accuracy_list.append(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a299_zpNqCPl"
      },
      "source": [
        "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd3B9DLwqCPm",
        "outputId": "460d494f-9497-4066-f0d9-c9bec894abda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.995"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "5pIXtrG8qCPm",
        "outputId": "c801cebc-fbb3-4e8c-caf0-0ae5c4e248be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(loss_list)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDIVD4PdqCPm"
      },
      "source": [
        "<h2 id=\"Question_3\">The misclassified samples</h2> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqV6KWZQqCPm"
      },
      "source": [
        "<b>The first four misclassified samples using the validation data:</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCGtIN6UqCPn",
        "outputId": "1e0ad3e9-ad64-4045-af4e-0ae2f97951b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample : 242; Expected Label: tensor([1]); Obtained Label: tensor([0])\n",
            "Sample : 310; Expected Label: tensor([1]); Obtained Label: tensor([0])\n",
            "Sample : 469; Expected Label: tensor([0]); Obtained Label: tensor([1])\n",
            "Sample : 653; Expected Label: tensor([0]); Obtained Label: tensor([1])\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "max_num_of_items = 4  # first four mis-classified samples\n",
        "validation_loader_batch_one = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)\n",
        "\n",
        "for i, (x_test, y_test) in enumerate(validation_loader_batch_one):\n",
        "    # set model to eval\n",
        "    model.eval()\n",
        "    \n",
        "    # make a prediction\n",
        "    z = model(x_test)\n",
        "    \n",
        "    # find max\n",
        "    _, yhat = torch.max(z.data, 1)\n",
        "    \n",
        "    # print mis-classified samples\n",
        "    if yhat != y_test:\n",
        "        print(\"Sample : {}; Expected Label: {}; Obtained Label: {}\".format(str(i), str(y_test), str(yhat)))\n",
        "        count += 1\n",
        "        if count >= max_num_of_items:\n",
        "            break\n",
        "    # end if\n",
        "# end for  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiO-R3vwqCPo"
      },
      "source": [
        "Copyright © 2018 <a href=\"https://cognitiveclass.ai/?utm_medium=dswb&utm_source=bducopyrightlink&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2022-01-01&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork20647850-2022-01-01\">MIT License</a>.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72df0417278f4a698d715a40631351b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef6ee786e998456e93d77cf3982ddb42",
              "IPY_MODEL_4db41434c958423d8a4608e5379fa8e9",
              "IPY_MODEL_472a995540044d96a5db2d9031b63842"
            ],
            "layout": "IPY_MODEL_77a53d05b2d7453d97d7180b209b765f"
          }
        },
        "ef6ee786e998456e93d77cf3982ddb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bfb8ee84d8648928020eaf68ac7cee8",
            "placeholder": "​",
            "style": "IPY_MODEL_a196af67e41f472da795049709b34dc3",
            "value": "100%"
          }
        },
        "4db41434c958423d8a4608e5379fa8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_516643faa6ac407699f0a4a356c0b689",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39f98be79d1c405bb20d15b8187df4d9",
            "value": 46830571
          }
        },
        "472a995540044d96a5db2d9031b63842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4a160da3c57443b937c9aab8839fa5b",
            "placeholder": "​",
            "style": "IPY_MODEL_d0353bd81de74a75a1470d042c5c095d",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 125MB/s]"
          }
        },
        "77a53d05b2d7453d97d7180b209b765f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bfb8ee84d8648928020eaf68ac7cee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a196af67e41f472da795049709b34dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "516643faa6ac407699f0a4a356c0b689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f98be79d1c405bb20d15b8187df4d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4a160da3c57443b937c9aab8839fa5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0353bd81de74a75a1470d042c5c095d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}